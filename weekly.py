# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xddulp3ToAz6RMaAOmZxoaWDXQ_3AdDt
"""

import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense,Dropout
from keras.layers import LSTM
from sklearn.metrics import mean_squared_error
from matplotlib import pyplot
import time
from math import sqrt
from sklearn.preprocessing import MinMaxScaler


n = 12000
file = np.load('polution_dataSet.npy')
len_data=int((len(file))/24)
a1 = np.zeros((len_data,8))
a2 = np.zeros((len_data,1))

bias=np.random.randint(24)
for i in range(len_data):
  a1[i] = file[24*i+bias,0:8]
  a2[i] = file[24*i+bias,0]

b1 = np.zeros((6,8))

train = int((len_data*0.64))-6
valid = int((len_data*0.16))-6

X_Valid = np.zeros((valid+1,6,8))
Y_Valid = np.zeros((valid+1,1))

X_Train = np.zeros((train+1,6,8))
Y_Train = np.zeros((train+1,1))

for i in range(train+1):
    for j in range(6):
        b1[j] = a1[j + i]
    X_Train[i] = b1
    Y_Train[i] = a2[6 + i]


for  i in range(valid + 1):
        iddx = i + train+6
        for j in range(6):
            b1[j] = a1[j+iddx]
        X_Valid[i] = b1
        Y_Valid[i] = a2[6 + iddx]

tstt = int((len_data*0.2))-6

X_Test = np.zeros((tstt,6,8))
Y_Test = np.zeros((tstt,1))
for  i in range(tstt):
    idx = train+valid +12+ i
    for j in range(6):
        b1[j] = a1[j + idx]

    X_Test[i] = b1
    Y_Test[i] = a2[6 + idx]

###########  LSTM

start = time.time()

model = Sequential()

model.add(LSTM(32,input_shape=(6,8),return_sequences=False, dropout=0.1, recurrent_dropout=0.1))
#model.add(Dropout(0.1))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='MAE', optimizer='adam', metrics=['accuracy'])## adam , RMSprop , ADAgrad
print(model.summary())
history = model.fit(X_Train, Y_Train, validation_data=(X_Valid, Y_Valid),verbose=2, epochs=100)

# Final evaluation of the model
scores = model.evaluate(X_Test, Y_Test, verbose=0)


print("Accuracy: %.2f%%" % (scores[1]*100))

done = time.time()
elapsed = done - start
print("Time of execution:   ",elapsed)



training_loss = history.history['loss']
test_loss = history.history['val_loss']
epoch_count = range(1, len(training_loss)+1)
pyplot.plot(epoch_count, training_loss)
pyplot.plot(epoch_count, test_loss)
pyplot.ylabel('Loss')
pyplot.xlabel('Epochs')
pyplot.legend(['Train', 'Test'], loc='upper right')
pyplot.show()

training_acc = history.history['accuracy']
test_acc = history.history['val_accuracy']
epoch_count = range(1, len(training_acc)+1)
pyplot.plot(epoch_count, training_acc)
pyplot.plot(epoch_count, test_acc)
pyplot.ylabel('Accuracy')
pyplot.xlabel('Epochs')
pyplot.legend(['Train', 'Test'], loc='upper right')
pyplot.show()


out1 = np.zeros(n)
out2 = np.zeros(n)


trainPredict = model.predict(X_Test)

fig, ax = pyplot.subplots(figsize=(17,8))
ax.set_title('Prediction vs. Actual after 100 epochs of training')
ax.plot(Y_Test[:,], label='True Data', color='green', linewidth='3')
ax.plot(trainPredict[:,], label='Prediction', color='red', linewidth='2')
pyplot.legend()
pyplot.show()

###########  RNN
start = time.time()


model = Sequential()
model.add(keras.layers.recurrent.SimpleRNN(32,input_shape=(6,8),return_sequences=False))
model.add(Dropout(0.1))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='mae', optimizer='adam', metrics=['accuracy'])#mean_squared_error   adam   RMSprop ADAgrad
print(model.summary())
history = model.fit(X_Train, Y_Train, validation_data=(X_Valid, Y_Valid),verbose=2, epochs=100)

# Final evaluation of the model
scores = model.evaluate(X_Test, Y_Test, verbose=0)


print("Accuracy: %.2f%%" % (scores[1]*100))

done = time.time()
elapsed = done - start
print("Time of execution:   ",elapsed)

training_loss = history.history['loss']
test_loss = history.history['val_loss']
epoch_count = range(1, len(training_loss)+1)
pyplot.plot(epoch_count, training_loss)
pyplot.plot(epoch_count, test_loss)
pyplot.ylabel('Loss')
pyplot.xlabel('Epochs')
pyplot.legend(['Train', 'Test'], loc='upper right')
pyplot.show()

training_acc = history.history['accuracy']
test_acc = history.history['val_accuracy']
epoch_count = range(1, len(training_acc)+1)
pyplot.plot(epoch_count, training_acc)
pyplot.plot(epoch_count, test_acc)
pyplot.ylabel('Accuracy')
pyplot.xlabel('Epochs')
pyplot.legend(['Train', 'Test'], loc='upper right')
pyplot.show()


out1 = np.zeros(n)
out2 = np.zeros(n)


trainPredict = model.predict(X_Test)



fig, ax = pyplot.subplots(figsize=(17,8))
ax.set_title('Prediction vs. Actual after 100 epochs of training')
ax.plot(Y_Test[:,], label='True Data', color='green', linewidth='3')
ax.plot(trainPredict[:,], label='Prediction', color='red', linewidth='2')
pyplot.legend()
pyplot.show()

###########  GRU


from math import sqrt

import numpy as np
from keras.layers import Dense, Dropout
from keras.layers import GRU
from keras.models import Sequential
from matplotlib import pyplot
from sklearn.metrics import mean_squared_error
import time
import math


start = time.time()

model = Sequential()
#model.add(GRU(16,input_shape=(24,8),return_sequences=True,activation='tanh',stateful=True,batch_input_shape=(1, 24, 8)))
#model.add(Dropout(0.3))
model.add(GRU(32,input_shape=(6,8), return_sequences=False,activation='tanh'))
model.add(Dropout(0.3))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='MAE', optimizer='RMSprop', metrics=['accuracy'])#mean_squared_error   adam   RMSprop    loss mae
print(model.summary())
history = model.fit(X_Train, Y_Train,validation_data=(X_Valid, Y_Valid),verbose=2, epochs=100, shuffle=False)

# Final evaluation of the model
scores = model.evaluate(X_Test, Y_Test, verbose=2)

print("Accuracy: %.2f%%" % (scores[1]*100))

done = time.time()
elapsed = done - start
print("Time of execution:   ",elapsed)

pyplot.figure()
training_loss = history.history['loss']
test_loss = history.history['val_loss']
epoch_count = range(1, len(training_loss)+1)
pyplot.plot(epoch_count, training_loss)
pyplot.plot(epoch_count, test_loss)
pyplot.title('Loss')
pyplot.ylabel('Loss')
pyplot.xlabel('Epochs')
pyplot.legend(['Train', 'Test'], loc='upper right')
pyplot.show()


start = time.time()
trainPredict = model.predict(X_Test)
done = time.time()
elapsed = done - start
print("Time of execution:   ",elapsed)

fig, ax = pyplot.subplots(figsize=(17,8))
ax.set_title('Prediction vs. Actual values after 50 epochs of training in single layer GRU')
ax.plot(Y_Test[:,], label='True Data', color='green', linewidth='3')
ax.plot(trainPredict[:,], label='Prediction', color='red', linewidth='2')
pyplot.legend()
pyplot.show()

