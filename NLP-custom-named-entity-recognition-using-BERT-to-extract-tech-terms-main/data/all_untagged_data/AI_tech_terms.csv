text,tech_terms
"Natural language processing [ 124 ] ( NLP ) allows machines to read and understand human language . A sufficiently powerful natural language processing system would enable natural-language user interfaces and the acquisition of knowledge directly from human-written sources , such as newswire texts . Some straightforward applications of natural language processing include information retrieval , text mining , question answering [ 125 ] and machine translation . [ 126 ] Many current approaches use word co-occurrence frequencies to construct syntactic representations of text . `` Keyword spotting `` strategies for search are popular and scalable but dumb ; a search query for `` dog `` might only match documents with the literal word `` dog `` and miss a document with the word `` poodle `` . `` Lexical affinity `` strategies use the occurrence of words such as `` accident `` to assess the sentiment of a document . Modern statistical NLP approaches can combine all these strategies as well as others , and often achieve acceptable accuracy at the page or paragraph level . Beyond semantic NLP , the ultimate goal of `` narrative `` NLP is to embody a full understanding of commonsense reasoning . [ 127 ] By 2019 , transformer-based deep learning architectures could generate coherent text .",[]
"Natural language processing ( NLP ) is a subfield of linguistics , computer science , and artificial intelligence concerned with the interactions between computers and human language , in particular how to program computers to process and analyze large amounts of natural language data . The result is a computer capable of `` understanding `` the contents of documents , including the contextual nuances of the language within them . The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves .",['Natural language processing']
"Challenges in natural language processing frequently involve speech recognition , natural language understanding , and natural-language generation .","['speech', 'natural']"
"A major drawback of statistical methods is that they require elaborate feature engineering . Since the early 2010s , [ 16 ] the field has thus largely abandoned statistical methods and shifted to neural networks for machine learning . Popular techniques include the use of word embeddings to capture semantic properties of words , and an increase in end-to-end learning of a higher-level task ( e.g . , question answering ) instead of relying on a pipeline of separate intermediate tasks ( e.g . , part-of-speech tagging and dependency parsing ) . In some areas , this shift has entailed substantial changes in how NLP systems are designed , such that deep neural network-based approaches may be viewed as a new paradigm distinct from statistical natural language processing . For instance , the term neural machine translation ( NMT ) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations , obviating the need for intermediate steps such as word alignment and language modeling that was used in statistical machine translation ( SMT ) . Latest works tend to use non-technical structure of a given task to build proper neural network .","['machine learning', '-', 'network', 'neural machine translation', 'learning', 'statistical machine translation', 'network']"
"Optical character recognition ( OCR ) : Given an image representing printed text , determine the corresponding text .",['Optical character recognition']
"Speech recognition : Given a sound clip of a person or people speaking , determine the textual representation of the speech . This is the opposite of text to speech and is one of the extremely difficult problems colloquially termed `` AI-complete `` ( see above ) . In natural speech there are hardly any pauses between successive words , and thus speech segmentation is a necessary subtask of speech recognition ( see below ) . In most spoken languages , the sounds representing successive letters blend into each other in a process termed coarticulation , so the conversion of the analog signal to discrete characters can be a very difficult process . Also , given that words in the same language are spoken by people with different accents , the speech recognition software must be able to recognize the wide variety of input as being identical to each other in terms of its textual equivalent .","['Speech', 'termed']"
"Speech segmentation : Given a sound clip of a person or people speaking , separate it into words . A subtask of speech recognition and typically grouped with it .",['Speech']
"Text-to-speech : Given a text , transform those units and produce a spoken representation . Text-to-speech can be used to aid the visually impaired . [ 18 ]",['Text']
"Word segmentation ( Tokenization ) : Separate a chunk of continuous text into separate words . For a language like English , this is fairly trivial , since words are usually separated by spaces . However , some written languages like Chinese , Japanese and Thai do not mark word boundaries in such a fashion , and in those languages text segmentation is a significant task requiring knowledge of the vocabulary and morphology of words in the language . Sometimes this process is also used in cases like bag of words ( BOW ) creation in data mining .",['Word segmentation']
"Named entity recognition ( NER ) : Given a stream of text , determine which items in the text map to proper names , such as people or places , and what the type of each such name is ( e.g . person , location , organization ) . Although capitalization can aid in recognizing named entities in languages such as English , this information can not aid in determining the type of named entity , and in any case , is often inaccurate or insufficient . For example , the first letter of a sentence is also capitalized , and named entities often span several words , only some of which are capitalized . Furthermore , many other languages in non-Western scripts ( e.g . Chinese or Arabic ) do not have any capitalization at all , and even languages with capitalization may not consistently use it to distinguish names . For example , German capitalizes all nouns , regardless of whether they are names , and French and Spanish do not capitalize names that serve as adjectives .",['Named entity recognition']
"Sentiment analysis ( see also multimodal sentiment analysis ) : Extract subjective information usually from a set of documents , often using online reviews to determine `` polarity `` about specific objects . It is especially useful for identifying trends of public opinion in social media , for marketing .","['Sentiment analysis', 'analysis']"
Terminology extraction : The goal of terminology extraction is to automatically extract relevant terms from a given corpus .,['Terminology extraction']
"Word sense disambiguation : Many words have more than one meaning ; we have to select the meaning which makes the most sense in context . For this problem , we are typically given a list of words and associated word senses , e.g . from a dictionary or an online resource such as WordNet .",['Word sense disambiguation']
"Relationship extraction : Given a chunk of text , identify the relationships among named entities ( e.g . who is married to whom ) .",[]
"Semantic Parsing : Given a piece of text ( typically a sentence ) , produce a formal representation of its semantics , either as a graph ( e.g . , in AMR parsing ) or in accordance with a logical formalism ( e.g . , in DRT parsing ) . This challenge typically includes aspects of several more elementary NLP tasks from semantics ( e.g . , semantic role labelling , word sense disambiguation ) and can be extended to include full-fledged discourse analysis ( e.g . , discourse analysis , coreference ; see Natural Language Understanding below ) .",[]
"Semantic Role Labelling : Given a single sentence , identify and disambiguate semantic predicates ( e.g . , verbal frames ) , then identify and classify the frame elements ( semantic roles ) .","['Semantic Role Labelling', 'semantic']"
"Automatic summarization ( text summarization ) : Produce a readable summary of a chunk of text . Often used to provide summaries of the text of a known type , such as research papers , articles in the financial section of a newspaper .",['Automatic summarization']
"Book generation : Not an NLP task proper but an extension of Natural Language Generation and other NLP tasks is the creation of full-fledged books . The first machine-generated book was created by a rule-based system in 1984 ( Racter , The policeman 's beard is half-constructed ) . [ 23 ] The first published work by a neural network was published in 2018 , 1 the Road , marketed as a novel , contains sixty million words . Both these systems are basically elaborate but non-sensical ( semantics-free ) language models . The first machine-generated science book was published in 2019 ( Beta Writer , Lithium-Ion Batteries , Springer , Cham ) . [ 24 ] Unlike Racter and 1 the Road , this is grounded on factual knowledge and based on text summarization .","['machine - generated', 'machine']"
Natural language generation ( NLG ) : Convert information from computer databases or semantic intents into readable human language .,['Natural language generation']
"Natural language understanding ( NLU ) : Convert chunks of text into more formal representations such as first-order logic structures that are easier for computer programs to manipulate . Natural language understanding involves the identification of the intended semantic from the multiple possible semantics which can be derived from a natural language expression which usually takes the form of organized notations of natural language concepts . Introduction and creation of language metamodel and ontology are efficient however empirical solutions . An explicit formalization of natural language semantics without confusions with implicit assumptions such as closed-world assumption ( CWA ) vs. open-world assumption , or subjective Yes/No vs. objective True/False is expected for the construction of a basis of semantics formalization . [ 30 ]","['Natural language understanding', 'language']"
"Question answering : Given a human-language question , determine its answer . Typical questions have a specific right answer ( such as `` What is the capital of Canada ? `` ) , but sometimes open-ended questions are also considered ( such as `` What is the meaning of life ? `` ) . Recent works have looked at even more complex questions . [ 31 ]",[]
"Computer vision is an interdisciplinary scientific field that deals with how computers can gain high-level understanding from digital images or videos . From the perspective of engineering , it seeks to understand and automate tasks that the human visual system can do .",[]
"The scientific discipline of computer vision is concerned with the theory behind artificial systems that extract information from images . The image data can take many forms , such as video sequences , views from multiple cameras , multi-dimensional data from a 3D scanner , or medical scanning device . The technological discipline of computer vision seeks to apply its theories and models to the construction of computer vision systems .","['computer', '3D scanner', 'computer']"
"Sub-domains of computer vision include scene reconstruction , event detection , video tracking , object recognition , 3D pose estimation , learning , indexing , motion estimation , visual servoing , 3D scene modeling , and image restoration .","['3D pose estimation', '3D scene']"
"Content-based image retrieval – finding all images in a larger set of images which have a specific content . The content can be specified in different ways , for example in terms of similarity relative a target image ( give me all images similar to image X ) , or in terms of high-level search criteria given as text input ( give me all images which contain many houses , are taken during winter , and have no cars in them ) .","['Content', 'image retrieval']"
Pose estimation – estimating the position or orientation of a specific object relative to the camera . An example application for this technique would be assisting a robot arm in retrieving objects from a conveyor belt in an assembly line situation or picking parts from a bin .,['Pose estimation']
"Optical character recognition ( OCR ) – identifying characters in images of printed or handwritten text , usually with a view to encoding the text in a format more amenable to editing or indexing ( e.g . ASCII ) .",['Optical character recognition']
2D code reading – reading of 2D codes such as data matrix and QR codes .,"['2D code', '2D codes', 'QR']"
Facial recognition,['Facial recognition']
Shape Recognition Technology ( SRT ) in people counter systems differentiating human beings ( head and shoulder patterns ) from objects,[]
"A few computer vision systems use image-acquisition hardware with active illumination or something other than visible light or both , such as structured-light 3D scanners , thermographic cameras , hyperspectral imagers , radar imaging , lidar scanners , magnetic resonance images , side-scan sonar , synthetic aperture sonar , etc . Such hardware captures `` images `` that are then processed often using the same computer vision algorithms used to process visible-light images .","['3D scanners', 'imagers', 'scanners', 'magnetic resonance', 'scan', 'aperture']"
"Machine perception is the capability of a computer system to interpret data in a manner that is similar to the way humans use their senses to relate to the world around them . [ 1 ] [ 2 ] [ 3 ] The basic method that the computers take in and respond to their environment is through the attached hardware . Until recently input was limited to a keyboard , or a mouse , but advances in technology , both in hardware and software , have allowed computers to take in sensory input in a way similar to humans . [ 1 ] [ 2 ]",['Machine perception']
"Machine perception allows the computer to use this sensory input , as well as conventional computational means of gathering information , to gather information with greater accuracy and to present it in a way that is more comfortable for the user . [ 1 ] These include computer vision , machine hearing , machine touch , and machine smelling .",['Machine perception']
"Active learning is a special case of machine learning in which a learning algorithm can interactively query a user ( or some other information source ) to label new data points with the desired outputs . [ 1 ] [ 2 ] [ 3 ] In statistics literature , it is sometimes also called optimal experimental design . [ 4 ] The information source is also called teacher or oracle .","['Active learning', 'machine learning']"
"Similarity learning is an area of supervised machine learning in artificial intelligence . It is closely related to regression and classification , but the goal is to learn a similarity function that measures how similar or related two objects are . It has applications in ranking , in recommendation systems , visual identity tracking , face verification , and speaker verification .","['Similarity learning', 'learning']"
"Unsupervised learning ( UL ) is a type of algorithm that learns patterns from untagged data . The hope is that through mimicry , the machine is forced to build a compact internal representation of its world . In contrast to Supervised Learning ( SL ) where data is tagged by a human , eg . as `` car `` or `` fish `` etc , UL exhibits self-organization that captures patterns as neuronal predelections or probability densities . [ 1 ] The other levels in the supervision spectrum are Reinforcement Learning where the machine is given only a numerical performance score as its guidance , and Semi-supervised learning where a smaller portion of the data is tagged . Two broad methods in UL are Neural Networks and Probabilistic Methods .","['Unsupervised learning', 'Learning', 'learning']"
"A recommender system , or a recommendation system ( sometimes replacing 'system ' with a synonym such as platform or engine ) , is a subclass of information filtering system that seeks to predict the `` rating `` or `` preference `` a user would give to an item . [ 1 ] [ 2 ] They are primarily used in commercial applications .",['recommender']
"Sparse coding is a representation learning method which aims at finding a sparse representation of the input data ( also known as sparse coding ) in the form of a linear combination of basic elements as well as those basic elements themselves . These elements are called atoms and they compose a dictionary . Atoms in the dictionary are not required to be orthogonal , and they may be an over-complete spanning set . This problem setup also allows the dimensionality of the signals being represented to be higher than the one of the signals being observed . The above two properties lead to having seemingly redundant atoms that allow multiple representations of the same signal but also provide an improvement in sparsity and flexibility of the representation .","['Sparse coding', 'sparse coding']"
"One of the most important applications of sparse dictionary learning is in the field of compressed sensing or signal recovery . In compressed sensing , a high-dimensional signal can be recovered with only a few linear measurements provided that the signal is sparse or nearly sparse . Since not all signals satisfy this sparsity condition , it is of great importance to find a sparse representation of that signal such as the wavelet transform or the directional gradient of a rasterized matrix . Once a matrix or a high dimensional vector is transferred to a sparse space , different recovery algorithms like basis pursuit , CoSaMP [ 1 ] or fast non-iterative algorithms [ 2 ] can be used to recover the signal .","['dictionary', 'sensing', 'sensing', 'dimensional']"
"In data analysis , anomaly detection ( also outlier detection ) [ 1 ] is the identification of rare items , events or observations which raise suspicions by differing significantly from the majority of the data . [ 1 ] Typically the anomalous items will translate to some kind of problem such as bank fraud , a structural defect , medical problems or errors in a text . Anomalies are also referred to as outliers , novelties , noise , deviations and exceptions .",[]
"Automated planning and scheduling , sometimes denoted as simply AI planning , [ 1 ] is a branch of artificial intelligence that concerns the realization of strategies or action sequences , typically for execution by intelligent agents , autonomous robots and unmanned vehicles . Unlike classical control and classification problems , the solutions are complex and must be discovered and optimized in multidimensional space . Planning is also related to decision theory .","['Automated', 'unmanned']"
"Affective computing is the study and development of systems and devices that can recognize , interpret , process , and simulate human affects . It is an interdisciplinary field spanning computer science , psychology , and cognitive science . [ 1 ] While some core ideas in the field may be traced as far back as to early philosophical inquiries into emotion , [ 2 ] the more modern branch of computer science originated with Rosalind Picard 's 1995 paper [ 3 ] on affective computing and her book Affective Computing [ 4 ] published by MIT Press . [ 5 ] [ 6 ] One of the motivations for the research is the ability to give machines emotional intelligence , including to simulate empathy . The machine should interpret the emotional state of humans and adapt its behavior to them , giving an appropriate response to those emotions .","['computing', 'Computing']"
"Artificial general intelligence ( AGI ) is the hypothetical [ 1 ] intelligence of a computer program that has the capacity to understand or learn any intellectual task that a human being can . It is a primary goal of some artificial intelligence research and a common topic in science fiction and futures studies . AGI can also be referred to as strong AI , [ 2 ] [ 3 ] [ 4 ] full AI , [ 5 ] or general intelligent action . [ 6 ] Some academic sources reserve the term `` strong AI `` for computer programs that can experience sentience , self-awareness and consciousness . [ 7 ] Today 's AI is speculated to be decades away from AGI .","['Artificial', 'AGI']"
"In June 2016 , a research team from the visual computing group of the Technical University of Munich and from Stanford University developed Face2Face , [ 77 ] a program which animates the face of a target person , transposing the facial expressions of an exterior source . The technology has been demonstrated animating the lips of people including Barack Obama and Vladimir Putin . Since then , other methods have been demonstrated based on deep neural network , from which the name `` deepfake `` was taken .",[]
Optical character recognition,['Optical character recognition']
Handwriting recognition,['Handwriting recognition']
Speech recognition,['Speech recognition']
Face recognition,['Face recognition']
Artificial creativity,['Artificial creativity']
Computer vision,['Computer vision']
Virtual reality,['Virtual reality']
Image processing,['Image processing']
Motion interpolation [ 144 ],['Motion interpolation']
Pixel-art scaling algorithms [ 145 ],['Pixel -']
Image scaling [ 146 ],['Image']
Image restoration [ 147 ] [ 148 ],['Image restoration']
Photo colorization [ 149 ],['Photo']
Film restoration [ 150 ],['Film']
Photo tagging [ 151 ],['Photo tagging']
Photo and video manipulation,[]
Diagnosis ( artificial intelligence ),"['Diagnosis', 'artificial intelligence']"
Game theory and strategic planning,[]
Game artificial intelligence and computer game bot,[]
"Natural language processing , translation and chatterbots",['Natural language']
Nonlinear control and robotics,['Nonlinear']
"Deep learning ( also known as deep structured learning ) is part of a broader family of machine learning methods based on artificial neural networks with representation learning . Learning can be supervised , semi-supervised or unsupervised . [ 1 ] [ 2 ] [ 3 ]","['Deep learning', 'deep', 'learning', 'machine learning']"
"Deep-learning architectures such as deep neural networks , deep belief networks , recurrent neural networks and convolutional neural networks have been applied to fields including computer vision , machine vision , speech recognition , natural language processing , audio recognition , social network filtering , machine translation , bioinformatics , drug design , medical image analysis , material inspection and board game programs , where they have produced results comparable to and in some cases surpassing human expert performance . [ 4 ] [ 5 ] [ 6 ] [ 7 ]","['Deep', 'learning architectures', 'deep', 'networks', 'networks', 'networks', 'networks']"
"Artificial neural networks ( ANNs ) were inspired by information processing and distributed communication nodes in biological systems . ANNs have various differences from biological brains . Specifically , neural networks tend to be static and symbolic , while the biological brain of most living organisms is dynamic ( plastic ) and analogue . [ 8 ] [ 9 ] [ 10 ]","['Artificial neural networks', 'networks']"
"The adjective `` deep `` in deep learning refers to the use of multiple layers in the network . Early work showed that a linear perceptron can not be a universal classifier , and then that a network with a nonpolynomial activation function with one hidden layer of unbounded width can on the other hand so be . Deep learning is a modern variation which is concerned with an unbounded number of layers of bounded size , which permits practical application and optimized implementation , while retaining theoretical universality under mild conditions . In deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models , for the sake of efficiency , trainability and understandability , whence the `` structured `` part .","['deep learning', 'learning']"
Automatic speech recognition,['Automatic speech recognition']
Image recognition,['Image recognition']
"Closely related to the progress that has been made in image recognition is the increasing application of deep learning techniques to various visual art tasks . DNNs have proven themselves capable , for example , of a ) identifying the style period of a given painting , b ) Neural Style Transfer - capturing the style of a given artwork and applying it in a visually pleasing manner to an arbitrary photograph or video , and c ) generating striking imagery based on random visual input fields .",['Transfer']
"Transfer learning ( TL ) is a research problem in machine learning ( ML ) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem . [ 1 ] For example , knowledge gained while learning to recognize cars could apply when trying to recognize trucks . This area of research bears some relation to the long history of psychological literature on transfer of learning , although formal ties between the two fields are limited . From the practical standpoint , reusing or transferring information from previously learned tasks for the learning of new tasks has the potential to significantly improve the sample efficiency of a reinforcement learning agent .","['Transfer learning', 'TL', 'machine learning']"
